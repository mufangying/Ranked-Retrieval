{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55f899d-b286-4e4b-a32e-e79efc2cd4a6",
   "metadata": {},
   "source": [
    "# Load & Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfc7cf-3126-48d2-b761-6477257a99ef",
   "metadata": {},
   "source": [
    "### Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1fae3-8b76-40f9-91dd-39dc9253a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = {}\n",
    "    all_scores = []\n",
    "    with open(file_path) as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            line_data = line.strip().split(',') \n",
    "            query_id = line_data[0]\n",
    "            doc_id = int(line_data[1])\n",
    "            label = int(line_data[2])\n",
    "            score = float(line_data[3])\n",
    "            all_scores.append(score)\n",
    "            doc_data = (doc_id, label, score)\n",
    "    \n",
    "            if query_id not in data.keys():\n",
    "                data[query_id] = list()\n",
    "            data[query_id].append(doc_data)\n",
    "\n",
    "    # sort the list so that they arrange in the descending order of their scores\n",
    "    for query_id in data.keys():\n",
    "        data[query_id] = sorted(data[query_id], key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return data, all_scores\n",
    "\n",
    "# l1_data, all_scores = load_data(l1_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713a971-e7a8-4542-8648-1e41ba131ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_file_name = \"/Volumes/Seagate/Data/MSMARCO/QuestionAnswering/dev_l1.txt\"\n",
    "l1_data, all_scores = load_data(l1_file_name)\n",
    "\n",
    "l2_file_name = \"/Volumes/Seagate/Data/MSMARCO/QuestionAnswering/dev_l2.txt\"\n",
    "l2_data, _ = load_data(l2_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e6cde-d2e5-419c-94f1-72ddaca08a93",
   "metadata": {},
   "source": [
    "### Convert score to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b58f5-e40f-4aa3-858d-2d116eeba425",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score_sum = 0 \n",
    "for i in all_scores:\n",
    "    total_score_sum += i\n",
    "average_score = total_score_sum / len(all_scores)\n",
    "\n",
    "import math\n",
    "for query_id in l1_data.keys():\n",
    "    l1_data[query_id] = [(d[0], d[1], math.tanh(d[2]/average_score)) for d in l1_data[query_id]]\n",
    "    \n",
    "for query_id in l2_data.keys():\n",
    "    l2_data[query_id] = [(d[0], d[1], (d[2]/100)) for d in l2_data[query_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438e1dbd-90b0-452f-a045-e1ca4676c69c",
   "metadata": {},
   "source": [
    "### Split to validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf68fa-db12-4740-86c7-23c5a36f394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_query_ids(data, split_ratio=0.5):\n",
    "    query_ids = list(data.keys())\n",
    "    num_queries = len(query_ids)\n",
    "    num_val = int (num_queries * split_ratio)\n",
    "    val_idx = set(random.sample(range(num_queries), num_val))\n",
    "    val_ids = [query_ids[idx] for idx in val_idx]\n",
    "    test_ids = [query_ids[idx] for idx in range(num_queries) if idx not in val_idx]\n",
    "    return val_ids, test_ids\n",
    "\n",
    "val_ids, test_ids = split_query_ids(l1_data, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b7701-c827-4da3-ae3e-ca0015e99721",
   "metadata": {},
   "source": [
    "### Zip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886deeb-ab27-40ba-929f-c09ac9a8a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_data(l1_data, l2_data, ids):\n",
    "    zipped_data = {}\n",
    "    for id in ids:\n",
    "        zipped_data[id] = (l1_data[id], l2_data[id])\n",
    "    return zipped_data\n",
    "val_zipped_data = zip_data(l1_data, l2_data, val_ids)\n",
    "test_zipped_data = zip_data(l1_data, l2_data, test_ids)\n",
    "\n",
    "print(test_zipped_data['0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44129272-97b0-4723-a7c7-a4592ac839bf",
   "metadata": {},
   "source": [
    "# Conformal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1185a5-3b38-4e65-8636-297bcbee2a0f",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c279e37-afd2-439e-b151-b87755453ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l1_risk_for_query(docs_for_query, threshold):\n",
    "    ground_truth_docs = get_ground_truth_above_l(docs_for_query, 1)\n",
    "    fetched_docs = set([doc[0] for doc in docs_for_query if doc[2] >= threshold])\n",
    "\n",
    "    num_fetched = len(ground_truth_docs.intersection(fetched_docs))\n",
    "    loss = 1 - num_fetched / (1.0 if len(ground_truth_docs) == 0 else len(ground_truth_docs))\n",
    "    return (loss, fetched_docs)\n",
    "\n",
    "def get_ground_truth_above_l(docs_for_query, relevance_level=1):\n",
    "    relevant_docs = [doc[0] for doc in docs_for_query if doc[1] >= relevance_level]\n",
    "    return set(relevant_docs)\n",
    "\n",
    "get_ground_truth_above_l(l1_data['1'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486aaf5-fb61-4688-9bfb-0c615c4d4647",
   "metadata": {},
   "source": [
    "### retrieval lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7a637-80d6-4f4f-93d2-c131a0346342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_retrieval_lambda(val_data, alpha):\n",
    "    pre_lambda_val = 0\n",
    "    lambda_val = 0.5\n",
    "    delta = abs(pre_lambda_val  - lambda_val) \n",
    "    precision = 0.00001\n",
    "    M = len(val_data.keys())\n",
    "    threshold = (M + 1) * alpha - 1\n",
    "    # print(threshold)\n",
    "    # iteration = 0\n",
    "    while delta >= precision:\n",
    "        total_loss = 0 \n",
    "        for query_id, (docs_for_query, _)  in val_data.items():\n",
    "            total_loss += calc_l1_risk_for_query(docs_for_query, lambda_val)[0]\n",
    "        # print(total_loss)\n",
    "        if total_loss > threshold:\n",
    "            lambda_val -= delta / 2\n",
    "        elif total_loss < threshold:\n",
    "            lambda_val += delta / 2\n",
    "        else:\n",
    "            break\n",
    "        pre_lambda_val = lambda_val\n",
    "        delta /= 2\n",
    "    return lambda_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706c10a-e2fb-485d-9f6a-1ed2bd0362d8",
   "metadata": {},
   "source": [
    "## Get maximal lambda_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff34202-d36b-4c78-9b1c-161ddff48b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l2_risk_for_query(l1_retrieved_docs, l2_ground_truth):\n",
    "    denominator = sum([1.0/math.log2(i+2) for i in range(len(l2_ground_truth))])\n",
    "    common_docs = set(l1_retrieved_docs).intersection(set(l2_ground_truth))\n",
    "    if len(common_docs) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        nominator = sum([1.0/math.log2(i+2) for i in range(len(common_docs))])\n",
    "    return 1 - nominator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47920dbb-3479-4d8f-bf1e-4ed79cdb9045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_retrieval_lambda(val_data, beta, level = 1):\n",
    "    pre_lambda_val = 0\n",
    "    lambda_val = 0.5\n",
    "    delta = abs(pre_lambda_val  - lambda_val) \n",
    "    precision = 0.0005\n",
    "    M = len(val_data.keys())\n",
    "    threshold = (M + 1) * beta - 1\n",
    "    while delta >= precision:\n",
    "        total_l2_loss = 0 \n",
    "        for query_id, (docs_for_query, _) in val_data.items():\n",
    "            l1_fetched_docs = set([doc[0] for doc in docs_for_query if doc[2] >= lambda_val])\n",
    "            l2_ground_truth_docs = set([doc[0] for doc in docs_for_query if doc[1] >= level])\n",
    "            min_l2_risk_for_query = calc_l2_risk_for_query(l1_fetched_docs, l2_ground_truth_docs)\n",
    "            total_l2_loss += min_l2_risk_for_query\n",
    "\n",
    "        if total_l2_loss > threshold:\n",
    "            lambda_val -= delta / 2\n",
    "        elif total_l2_loss < threshold:\n",
    "            lambda_val += delta / 2\n",
    "        else:\n",
    "            break\n",
    "        pre_lambda_val = lambda_val\n",
    "        delta /= 2\n",
    "        \n",
    "    # calc l1 risk\n",
    "    total_l1_loss = 0\n",
    "    for query_id, (docs_for_query, _) in val_data.items():\n",
    "        l1_risk_for_query, _ = calc_l1_risk_for_query(docs_for_query, lambda_val)\n",
    "        total_l1_loss += l1_risk_for_query\n",
    "    alpha = (total_l1_loss + 1)/(M + 1)\n",
    "    \n",
    "    return lambda_val, alpha\n",
    "\n",
    "max_l1_lambda, alpha = get_max_retrieval_lambda(val_zipped_data, 0.3)\n",
    "print(max_l1_lambda)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42cc376-5662-4848-bf7f-eb55107d822e",
   "metadata": {},
   "source": [
    "## Change beta but fix alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88de8a8-e4b2-4eae-affc-570655441ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iteration_times = 10\n",
    "precision = 0.0005\n",
    "num_lambda_steps = 21\n",
    "\n",
    "alpha = 0.3\n",
    "\n",
    "summary_by_beta = {}\n",
    "\n",
    "for beta in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]:\n",
    "    for iteration in range(iteration_times):     \n",
    "        val_ids, test_ids = split_query_ids(l1_data, 0.5)\n",
    "        val_zipped_data = zip_data(l1_data, l2_data, val_ids)\n",
    "        test_zipped_data = zip_data(l1_data, l2_data, test_ids)\n",
    "\n",
    "\n",
    "        max_l1_lambda_1 = calc_retrieval_lambda(val_zipped_data, alpha)\n",
    "        (max_l1_lambda_2,_) = get_max_retrieval_lambda(val_zipped_data, beta)\n",
    "        max_l1_lambda = min(max_l1_lambda_1, max_l1_lambda_2)\n",
    "        \n",
    "        lambda_grid = np.linspace(0, max_l1_lambda, num=num_lambda_steps)\n",
    "        best_prediction_size = 10000000\n",
    "        best_l1_size, best_l2_size = 0, 0\n",
    "        best_alpha, best_beta = 0, 0\n",
    "        for l1_lambda_val in lambda_grid:\n",
    "            pre_l2_lambda_val = 0\n",
    "            l2_lambda_val = 0.5\n",
    "            delta = abs(pre_l2_lambda_val  - l2_lambda_val) \n",
    "            M = len(val_zipped_data.keys())\n",
    "            threshold = (M + 1) * beta - 1\n",
    "            while delta >= precision:\n",
    "                total_loss = 0 \n",
    "                for query_id, (l1_docs_for_query, l2_docs_for_query) in val_zipped_data.items():\n",
    "                    l1_fetched_docs = set([doc[0] for doc in l1_docs_for_query if doc[2] >= l1_lambda_val])\n",
    "                    l2_retained_docs = set([doc[0] for doc in l2_docs_for_query if doc[2] >= l2_lambda_val and doc[0] in l1_fetched_docs])\n",
    "                    l2_ground_truth_docs = set([doc[0] for doc in l2_docs_for_query if doc[1] >= level])\n",
    "                    l2_risk_for_query = calc_l2_risk_for_query(l2_retained_docs, l2_ground_truth_docs)\n",
    "                    total_loss += l2_risk_for_query\n",
    "                    \n",
    "                if total_loss > threshold:\n",
    "                    l2_lambda_val -= delta / 2\n",
    "                elif total_loss < threshold:\n",
    "                    l2_lambda_val += delta / 2\n",
    "                else:\n",
    "                    break\n",
    "                pre_l2_lambda_val = l2_lambda_val\n",
    "                delta /= 2\n",
    "\n",
    "            ## verify control on test data\n",
    "            total_l1_size, total_l2_size = 0, 0\n",
    "            total_l1_loss, total_l2_loss = 0, 0\n",
    "            M_test = len(val_zipped_data.keys())\n",
    "            for query_id, (l1_docs_for_query, l2_docs_for_query) in test_zipped_data.items():\n",
    "                l1_fetched_docs = set([doc[0] for doc in l1_docs_for_query if doc[2] >= l1_lambda_val])\n",
    "                l1_ground_truth = set([doc[0] for doc in l1_docs_for_query if doc[1] >= level])\n",
    "                total_l1_size += len(l1_fetched_docs)\n",
    "                total_l1_loss += 1 - len(l1_ground_truth.intersection(l1_fetched_docs)) / (1.0 if len(l1_ground_truth) == 0 else len(l1_ground_truth))\n",
    "                l2_retained_docs = set([doc[0] for doc in l2_docs_for_query if doc[2] >= l2_lambda_val and doc[0] in l1_fetched_docs])\n",
    "                total_l2_size += len(l2_retained_docs)\n",
    "                l2_ground_truth_docs = set([doc[0] for doc in l2_docs_for_query if doc[1] >= level])\n",
    "                l2_risk_for_query = calc_l2_risk_for_query(l2_retained_docs, l2_ground_truth_docs)\n",
    "                total_l2_loss += l2_risk_for_query\n",
    "    \n",
    "            avg_l1_loss = (total_l1_loss + 1)/(M_test + 1)\n",
    "            avg_l2_loss = (total_l2_loss + 1)/(M_test + 1)\n",
    "            avg_l1_size = total_l1_size / M_test\n",
    "            avg_l2_size = total_l2_size / M_test\n",
    "            prediction_size = avg_l1_size + avg_l2_size\n",
    "            if prediction_size < best_prediction_size:\n",
    "                best_prediction_size = prediction_size\n",
    "                best_l1_size = avg_l1_size\n",
    "                best_l2_size = avg_l2_size\n",
    "                best_alpha = avg_l1_loss\n",
    "                best_beta = avg_l2_loss\n",
    "                \n",
    "        print('{}:{}:{}:{}:{}:{}'.format(beta, best_prediction_size, best_l1_size, best_l2_size, best_alpha, best_beta))\n",
    "        if beta not in summary_by_beta.keys():\n",
    "            summary_by_beta[beta] = list()\n",
    "        summary_by_beta[beta].append((best_prediction_size, best_l1_size, best_l2_size, best_alpha, best_beta))\n",
    "\n",
    "# print(summary_by_beta[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099a7c3-482d-4b2b-a3cd-1a1595c2c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta, results in summary_by_beta.items():\n",
    "    iteration_times = len(results)\n",
    "    total_pred_size, total_l1_size, total_l2_size, total_l1_loss, total_l2_loss = 0, 0, 0, 0, 0\n",
    "    for tuple in results:\n",
    "        total_pred_size += tuple[0]\n",
    "        total_l1_size += tuple[1]\n",
    "        total_l2_size += tuple[2]\n",
    "        total_l1_loss += tuple[3]\n",
    "        total_l2_loss += tuple[4]\n",
    "    print('{}:{}:{}:{}:{}:{}'.format(beta, total_pred_size / iteration_times, total_l1_size / iteration_times,\n",
    "                                  total_l2_size / iteration_times, total_l1_loss / iteration_times, total_l2_loss / iteration_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b61430-29e0-4ef3-b83b-9848c444bd65",
   "metadata": {},
   "source": [
    "## Fixed beta but change alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fbcacb-b2a8-4f82-95b7-f59ca93f2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "iteration_times = 100\n",
    "level = 1\n",
    "precision = 0.0005\n",
    "num_lambda_steps = 21\n",
    "\n",
    "beta = 0.2\n",
    "\n",
    "summary_by_alpha = {}\n",
    "\n",
    "for alpha in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]:\n",
    "    for iteration in range(iteration_times):     \n",
    "        val_ids, test_ids = split_query_ids(l1_data, 0.5)\n",
    "        val_zipped_data = zip_data(l1_data, l2_data, val_ids)\n",
    "        test_zipped_data = zip_data(l1_data, l2_data, test_ids)\n",
    "\n",
    "\n",
    "        max_l1_lambda_1 = calc_retrieval_lambda(val_zipped_data, alpha)\n",
    "        (max_l1_lambda_2,_) = get_max_retrieval_lambda(val_zipped_data, beta)\n",
    "        max_l1_lambda = min(max_l1_lambda_1, max_l1_lambda_2)\n",
    "        \n",
    "        # max_l1_lambda, _ = get_max_retrieval_lambda(val_zipped_data, beta, level)\n",
    "        # print(max_l1_lambda)\n",
    "        lambda_grid = np.linspace(0, max_l1_lambda, num=num_lambda_steps)\n",
    "        # print(lambda_grid)\n",
    "        best_prediction_size = 10000000\n",
    "        best_l1_size, best_l2_size = 0, 0\n",
    "        best_alpha, best_beta = 0, 0\n",
    "        for l1_lambda_val in lambda_grid:\n",
    "            pre_l2_lambda_val = 0\n",
    "            l2_lambda_val = 0.5\n",
    "            delta = abs(pre_l2_lambda_val  - l2_lambda_val) \n",
    "            M = len(val_zipped_data.keys())\n",
    "            threshold = (M + 1) * beta - 1\n",
    "            while delta >= precision:\n",
    "                total_loss = 0 \n",
    "                for query_id, (l1_docs_for_query, l2_docs_for_query) in val_zipped_data.items():\n",
    "                    l1_fetched_docs = set([doc[0] for doc in l1_docs_for_query if doc[2] >= l1_lambda_val])\n",
    "                    l2_retained_docs = set([doc[0] for doc in l2_docs_for_query if doc[2] >= l2_lambda_val and doc[0] in l1_fetched_docs])\n",
    "                    l2_ground_truth_docs = set([doc[0] for doc in l2_docs_for_query if doc[1] >= level])\n",
    "                    l2_risk_for_query = calc_l2_risk_for_query(l2_retained_docs, l2_ground_truth_docs)\n",
    "                    total_loss += l2_risk_for_query\n",
    "                    \n",
    "                if total_loss > threshold:\n",
    "                    l2_lambda_val -= delta / 2\n",
    "                elif total_loss < threshold:\n",
    "                    l2_lambda_val += delta / 2\n",
    "                else:\n",
    "                    break\n",
    "                pre_l2_lambda_val = l2_lambda_val\n",
    "                delta /= 2\n",
    "\n",
    "            ## verify control on test data\n",
    "            total_l1_size, total_l2_size = 0, 0\n",
    "            total_l1_loss, total_l2_loss = 0, 0\n",
    "            M_test = len(val_zipped_data.keys())\n",
    "            for query_id, (l1_docs_for_query, l2_docs_for_query) in test_zipped_data.items():\n",
    "                l1_fetched_docs = set([doc[0] for doc in l1_docs_for_query if doc[2] >= l1_lambda_val])\n",
    "                l1_ground_truth = set([doc[0] for doc in l1_docs_for_query if doc[1] >= level])\n",
    "                total_l1_size += len(l1_fetched_docs)\n",
    "                total_l1_loss += 1 - len(l1_ground_truth.intersection(l1_fetched_docs)) / (1.0 if len(l1_ground_truth) == 0 else len(l1_ground_truth))\n",
    "                l2_retained_docs = set([doc[0] for doc in l2_docs_for_query if doc[2] >= l2_lambda_val and doc[0] in l1_fetched_docs])\n",
    "                total_l2_size += len(l2_retained_docs)\n",
    "                l2_ground_truth_docs = set([doc[0] for doc in l2_docs_for_query if doc[1] >= level])\n",
    "                l2_risk_for_query = calc_l2_risk_for_query(l2_retained_docs, l2_ground_truth_docs)\n",
    "                total_l2_loss += l2_risk_for_query\n",
    "    \n",
    "            avg_l1_loss = (total_l1_loss + 1)/(M_test + 1)\n",
    "            avg_l2_loss = (total_l2_loss + 1)/(M_test + 1)\n",
    "            avg_l1_size = total_l1_size / M_test\n",
    "            avg_l2_size = total_l2_size / M_test\n",
    "            prediction_size = avg_l1_size + avg_l2_size\n",
    "            if prediction_size < best_prediction_size:\n",
    "                best_prediction_size = prediction_size\n",
    "                best_l1_size = avg_l1_size\n",
    "                best_l2_size = avg_l2_size\n",
    "                best_alpha = avg_l1_loss\n",
    "                best_beta = avg_l2_loss\n",
    "                \n",
    "        print('{}:{}:{}:{}:{}:{}'.format(alpha, best_prediction_size, best_l1_size, best_l2_size, best_alpha, best_beta))\n",
    "        if alpha not in summary_by_alpha.keys():\n",
    "            summary_by_alpha[alpha] = list()\n",
    "        summary_by_alpha[alpha].append((best_prediction_size, best_l1_size, best_l2_size, best_alpha, best_beta))\n",
    "\n",
    "# print(summary_by_alpha[0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80e72e-30b6-4ca3-bbc2-741648e3e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha, results in summary_by_alpha.items():\n",
    "    iteration_times = len(results)\n",
    "    total_pred_size, total_l1_size, total_l2_size, total_l1_loss, total_l2_loss = 0, 0, 0, 0, 0\n",
    "    for tuple in results:\n",
    "        total_pred_size += tuple[0]\n",
    "        total_l1_size += tuple[1]\n",
    "        total_l2_size += tuple[2]\n",
    "        total_l1_loss += tuple[3]\n",
    "        total_l2_loss += tuple[4]\n",
    "    print('{}:{}:{}:{}:{}:{}'.format(alpha, total_pred_size / iteration_times, total_l1_size / iteration_times,\n",
    "                                  total_l2_size / iteration_times, total_l1_loss / iteration_times, total_l2_loss / iteration_times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
